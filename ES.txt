实例项目：https://gitee.com/52itstyle/spring-boot-elasticsearch

https://blog.csdn.net/weixin_34190136/article/details/91446546
ES基于apache lucene之上的开源分布式搜素引擎(elasticsearch-head是一个界面化的集群操作和管理工具)
ES还是一个分布式文档数据库（非结构化 的数据库），其中每个字段均可被索引，而且每个字段的数据均可被搜索，能够横向扩展至数以百计的服务器存储以及处理PB级的数据
近实时（NRT）
ES是一个近实时的搜索引擎（平台），代表着从添加数据到能被搜索到只有很少的延迟。（大约是1s）

索引:索引是具有某种相似特性的文档集合
文档：一个文档是一个可被索引的基础信息单元



#创建索引
curl -X PUT "localhost:9200/customer"
#创建文档（添加数据）
curl -X PUT "localhost:9200/customer/_doc/1" -H 'Content-Type: application/json' -d'{  "name": "John Doe"}'
#查询文档（查询数据）
curl -X GET "localhost:9200/customer/_doc/1"
#删除文档（删除数据）
curl -X DELETE "localhost:9200/customer"

95589









Elasticsearch 与 Solr 的比较总结
二者安装都很简单；
Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;
Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；
Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；
Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。
Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。

其他基于Lucene的开源搜索引擎解决方案*
直接使用 Lucene
说明：Lucene 是一个 JAVA 搜索类库，它本身并不是一个完整的解决方案，需要额外的开发工作。

kibana:https://www.cnblogs.com/cjsblog/p/9476813.html
Logstash介绍 https://www.cnblogs.com/cjsblog/p/9459781.html

CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于网络硬件肯定会出现延迟丢包等问题，所以分区容错性是我们必须需要实现的



https://www.elastic.co/cn/downloads/elasticsearch

elasticsearch / 123456
B-Tree索引(mysql)
B+Tree

https://gitee.com/52itstyle/spring-boot-elasticsearch

kibana :https://artifacts.elastic.co/downloads/kibana/kibana-6.8.0-linux-x86_64.tar.gz


Elasticsearch可视化插件head

Elasticsearch安装(需要先安装JDK)
1.下载安装包：wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.4.2-linux-x86_64.tar.gz

2.解压 tar -zxf elasticsearch-6.8.0.tar.gz

3.需要新建elasticsearch组及用户，用以来启动
# 以root用户来创建新的用户 ， groupadd 添加一个用户组
[root@localhost home]# groupadd elasticsearch 
# 添加一个用户，-g是在用户组下 -p是密码
[root@localhost home]# useradd elasticsearch -g elasticsearch -p elasticsearch
# 进入es的安装目录
[root@localhost home]# cd /home/elasticsearch 
# 给用户elasticsearch 授权 修改文件拥有者
[root@localhost home]# chown -R elasticsearch:elasticsearch elasticsearch-6.1.2/
# 切换到 elasticsearch 用户
[root@localhost elasticsearch]# su elasticsearch

4.修改IP Port
vi config/elasticsearch.yml

4.1修改其他相关配置：
使用ROOT用户修改
vi /etc/security/limits.conf

修改线程文件数量 指定到elasticsearch用户，用“*” 则匹配所有用户(通过ulimit -Hn查看)
elasticsearch hard nofile 65536 //每个进程最大同时打开文件数
elasticsearch soft nofile 65536

elasticsearch soft nproc 4096 //最大线程个数
elasticsearch hard nproc 4096

修改虚机最大内存/etc/sysctl.conf文件，增加配置vm.max_map_count=262144
vi /etc/sysctl.conf
sysctl -p

5.启动
一定要先切换成elasticsearch用户 再启动！！！！
 ./bin/elasticsearch
后台启动 加参数-d ./bin/elasticsearch -d
 ./bin/elasticsearch -d && tail -f logs/elasticsearch.log

6.查看进程jps
7.检查elasticsearch运行情况：curl http://localhost:9200/

8.ES相关命令
查看集群健康
curl -X GET "172.16.100.122:9200/_cat/health?v"

查看集群结点列表
curl -X GET "172.16.100.122:9200/_cat/nodes?v"

安装IK分词器 https://github.com/medcl/elasticsearch-analysis-ik
在线安装：
1.执行命令：./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.8.0/elasticsearch-analysis-ik-6.8.0.zip
2.离线解压安装：
https://github.com/medcl/elasticsearch-analysis-ik/releases 下地最新分词器并解压文件至es安装目录plugins目录下，重启ES即可

=========================================================================
安装elasticsearch-head
elasticsearch-head是一个用于浏览ElasticSearch集群并与其进行交互的Web项目
1.yum -y install nodejs npm
2.yum -y install git
3.git clone https://github.com/mobz/elasticsearch-head.git
4.克隆下GIT项目后进行编译处理
cd elasticsearch-head/
npm install --registry=https://registry.npm.taobao.org

5.修改elasticsearch.yml，增加跨域的配置(需要重启es才能生效)
vi /etc/elasticsearch/elasticsearch.yml
增加如下内容
http.cors.enabled: true
http.cors.allow-origin: "*"

6.修改Gruntfile.js文件，修改服务监听地址（增加hostname属性，将其值设置为*）
connect:{
  server:{
  	options:{
  		hostname:'*',
  		port:9100
  	}
  }
}

7.修改head/_site/app.js，修改head连接es的地址（修改localhost为本机的IP地址）
this.base_uri=this.config.base_uri||this.prefs.get("app-base_uri")||"172.16.100.122:9200";

8.启动插件
elasticsearch-head安装目录下执行
npm run start &

9.访问
http://172.16.100.122:9100/

备注：
#使用淘宝的镜像源来安装grunt程序，grunt是基于nodejs的项目构建工具，可以进行打包压缩、测试、执行等工作，head插件就是通过grunt启动。
npm install -g grunt --registry=https://registry.npm.taobao.org

#安装grunt工具的客户端
npm install -g grunt-cli --registry=https://registry.npm.taobao.org 


================================================================

安装kibana( Kibana 是为 Elasticsearch设计的开源分析和可视化平台)
1.下载安装包：wget https://artifacts.elastic.co/downloads/kibana/kibana-6.8.0-linux-x86_64.tar.gz
2.解压tar -zxf kibana-6.8.0-linux-x86_64.tar.gz
3.修改安装目录config/kibana.yml
4.启动命令./bin/kibana &
5.查看进程：ps -ef|grep node
或：netstat -tunlp|grep 5601


----------------------------------------------
logstash安装
1.下载wget https://artifacts.elastic.co/downloads/logstash/logstash-6.8.0.tar.gz
2.解压
tar -zxvf logstash-2.3.1.tar.gz -C /bigdata/

3.修改配置
vi logstash.conf
input {
	file {
		type => "gamelog"
		path => "/log/*/*.log"
		discover_interval => 10
		start_position => "beginning" 
	}
}
 
output {
    elasticsearch {
		index => "gamelog-%{+YYYY.MM.dd}"
        hosts => ["172.16.0.14:9200", "172.16.0.15:9200", "172.16.0.16:9200"]
    }
}

说明：
#discover_interval=> 15  //设置多长时间扫描目录，发现新文件单位MS
#stat_interval=> 1 //设置多长时间检测文件是否修改 默认为1MS

4.启动：
bin/logstash -f logstash.conf
或
后台启动 nohup bin/logstash -f config/kafka.conf & tail -f nohup.out

直接启动：
bin/logstash -e 'input { stdin {} } output { stdout{} }'

bin/logstash -e 'input { stdin {} } output { stdout{codec => rubydebug} }'

bin/logstash -e 'input { stdin {} } output { elasticsearch {hosts => ["172.16.0.14:9200"]} stdout{} }'

bin/logstash -e 'input { stdin {} } output { elasticsearch {hosts => ["172.16.0.15:9200", "172.16.0.16:9200"]} stdout{} }'

bin/logstash -e 'input { stdin {} } output { kafka { topic_id => "test" bootstrap_servers => "172.16.0.11:9092,172.16.0.12:9092,172.16.0.13:9092"} stdout{codec => rubydebug} }'


脚本方式后台启动
vim /opt/elogstash/logstash-6.5.1/startup.sh
nohup bin/logstash -f config/kafka.conf &
./startup.sh 即可后台启动
tail -f nohup.out 可查看启动日志

ELK日志系统 搭建教程：http://www.imooc.com/article/266484
logstash 开源的日志收集引擎，具备实时传输的能力

logstash配置示例
input {
        file {
                type => "biplog"
                path => "/opt/tj_bip/nohup.out"
                discover_interval => 10
                start_position => "beginning" 
        }
}
 
output {
    elasticsearch {
                index => "biplog-%{+YYYY.MM.dd}"
        hosts => ["172.16.100.122:9200"]
    }
}


=========================================================
elasticsearch 之 _mapping映射
1.映射（mapping）相当于数据库表的表结构
2.ES中的映射用来定义一个文档，可以定义文档所包含的字段及字段类型，分词器及属性等等
3.ES映射分为动态映射（文档写入ElasticSearch时，会根据文档字段自动识别类型，这种机制称之为动态映射）及静态映射（事先定义好映射，包含文档的各个字段及其类型等，这种方式称之为静态映射）
4.Near Realtime (NRT)近乎实时的搜索平台，从索引文档到可以搜索的时间只有轻微的延迟（通常是1秒）
5.Cluster：集群是一个或多个节点(服务器)的集合，它们共同保存你的整个数据，并提供跨所有节点的联合索引和搜索功能
6.Node：节点是一个单独的服务器，它是集群的一部分，存储数据，并参与集群的索引和搜索功能
7.index :索引是具有某种相似特征的文档的集合
8.Document:文档是可以被索引的基本信息单元。文档用JSON表示
9.Shards & Replicas分片及副本[分片好处：允许水平分割扩展，允许跨分片（可能在多个结点）分布和并行操作，提高性能及吞吐量]
副本：高可用性，扩展的搜索吞吐量，搜索可以在所有副本上并行执行。

10.Elasticsearch 中数据最重要的三要素当属：索引、类型、文档
10.1索引：
 10.1.1settings是修改分片(number_of_shards)和副本数(number_of_replicas)的。
 10.1.2mappings是修改字段和类型的。
 mapping中的字段类型一旦设置，禁止直接修改，因为 lucene实现的倒排索引生成后不允许修改，应该重新建立新的索引，然后做reindex操作
 
 
检查ES是否在运行：
curl http://localhost:9200/

查看ES集群健康:
curl -X GET "localhost:9200/_cat/health?v"

查看ES结点列表：
curl -X GET "localhost:9200/_cat/nodes?v"

查看ES所有索引
curl -X GET "localhost:9200/_cat/indices?v"

创建一个索引
curl -X PUT "localhost:9200/index名称?pretty"  //创建一个名称为index名称 的索引并以漂亮的JSON格式返回

创建一个索引并添加一个映射
curl -X PUT "localhost:9200/indexName" -H 'Content-Type:application/json' -d
'{
  mappings:{
    "dynamic":false  # false表示在写入文档时，如果写入字段不存在也不会报错。
    "_doc":{
       "properties":{
       		"fieldName":{
       			"type":"text",
       			"index":true, #index参数作用是控制当前字段是否被索引，默认为true，false表示不记录，即不可被搜索
       			"null_value":"" # 这个参数的作用是当字段遇到null值的时候的处理策略，默认为null，即空值，此时es会忽略该值。可以通过这个参数设置某个字段的默认值
       		},
       }
    }
  }
}'
或
PUT my_index
{
  mappings:{
    
  }
}


索引一个文档
curl -X PUT "172.16.100.122:9200/fang-test/test/1000?pretty" -H 'Content-Type:application/json' -d '{"name":"fanghj","job":"it"}'
或
PUT /indexName/_doc/id 
{
 "name":"fanghj",
 "job":"it"
}

查询写入文档：
GET /indexName/_doc/_search
{
 "query":{
   "match":{
   		"name":"fanghj"
   }
 }
}
或者
curl -X GET "172.16.100.122:9200/fang-test/test/_search?pretty" -H 'Content-Type:application/json' -d '{"query":{"match":{"name":"fanghj"}}}'


查看mapping:
GET /[index_name]/_mapping





备注：-X参数指定 HTTP 请求的方法。
wget命令用来从指定的URL下载文件

查看索引配置settings信息
GET /索引名/_settings?pretty
或 curl -X GET "locahost:9200/customer/_settins?pretty"



说明：
?v是用来要求在结果中返回表头
?pretty要求返回一个漂亮的json结果



                                                                                            